modified this repo for optimisation:
https://github.com/Jitendra-DataScientist/RAG/

1. reference documents' contents not to be sent in response to save context window.
2. used NVIDEA's meta/llama-3.3-70b-instruct model instead of meta/llama3-70b-instruct.
3. increased max_tokens from 1024 to 128000.
